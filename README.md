# RAG Transformer - å¤šGPUè®­ç»ƒæ¡†æ¶

ä¸€ä¸ªç®€æ´é«˜æ•ˆçš„å¤šGPUæ·±åº¦å­¦ä¹ è®­ç»ƒæ¡†æ¶ï¼Œä¸“æ³¨äºTransformerå’ŒMambaæ¨¡å‹è®­ç»ƒã€‚

## ğŸš€ ç‰¹æ€§

- **åŒæ¨¡å‹æ”¯æŒ**: Transformerå’ŒMambaçŠ¶æ€ç©ºé—´æ¨¡å‹
- **å¤šGPUè®­ç»ƒ**: æ”¯æŒ1-8ä¸ªGPUå¹¶è¡Œè®­ç»ƒï¼ˆPyTorch DDPï¼‰
- **æ™ºèƒ½æ‰¹å¤§å°**: è‡ªåŠ¨æ ¹æ®GPUæ•°é‡å’Œæ¨¡å‹ç±»å‹ä¼˜åŒ–æ‰¹å¤§å°
- **YAMLé…ç½®**: ç®€å•ç›´è§‚çš„é…ç½®æ–‡ä»¶ç³»ç»Ÿ
- **æ˜¾å­˜ä¼˜åŒ–**: è‡ªåŠ¨ä¼°ç®—æ˜¾å­˜éœ€æ±‚ï¼Œé¿å…OOMé”™è¯¯
- **å³å¼€å³ç”¨**: é¢„é…ç½®çš„è®­ç»ƒè„šæœ¬ï¼Œå¿«é€Ÿä¸Šæ‰‹
- **è‡ªåŠ¨å…³æœº**: è®­ç»ƒå®Œæˆåå¯è‡ªåŠ¨å…³æœºï¼ˆå¯é€‰ï¼‰

## ğŸ“‹ ç¯å¢ƒè¦æ±‚

- Python 3.8+
- CUDA 11.0+
- PyTorch 2.0+
- æ”¯æŒçš„GPU: RTX 3090/4090, A100ç­‰

## ğŸ› ï¸ å®‰è£…

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd "RAG Transformer"

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒæ£€æŸ¥
```bash
# å¿«é€ŸéªŒè¯ç¯å¢ƒå’Œä¾èµ–
python quick_test.py
```

### 2. æŸ¥çœ‹å¯ç”¨é…ç½®
```bash
# æŸ¥çœ‹é¢„è®¾æ¨¡å‹é…ç½®
python train.py --list_presets

# æŸ¥çœ‹å¯ç”¨æ•°æ®é›†
python train.py --list_datasets

# æŸ¥çœ‹å¯ç”¨æ¨¡å‹
python train.py --list_models
```

### 3. é€‰æ‹©è®­ç»ƒè§„æ¨¡
```bash
# 1Bæ¨¡å‹è®­ç»ƒ (é€‚åˆå•å¡RTX 4090)
python train.py --preset 1b_transformer

# 7Bæ¨¡å‹è®­ç»ƒ (éœ€è¦4å¡ä»¥ä¸Š)
python train.py --preset 7b_transformer --num_gpus 4

# Mambaæ¨¡å‹ (æ˜¾å­˜æ•ˆç‡æ›´é«˜)
python train.py --preset 1b_mamba
```

### 4. æ•°æ®é›†ç®¡ç†
```bash
# æµè§ˆæ‰€æœ‰å¯ç”¨æ•°æ®é›†
python list_datasets.py

# æŸ¥çœ‹1Bæ¨¡å‹æ¨èæ•°æ®é›†
python list_datasets.py --recommend 1B

# æŸ¥çœ‹7Bæ¨¡å‹æ¨èæ•°æ®é›†
python list_datasets.py --recommend 7B

# ä¸‹è½½æŒ‡å®šæ•°æ®é›†
python list_datasets.py --download wikitext
```

### 5. æµ‹è¯•GPUè®¾ç½®
```bash
python test_multi_gpu.py
```

### 6. éªŒè¯é…ç½®
```bash
python train.py --dry_run
```

### 7. å¼€å§‹è®­ç»ƒ

**å•GPUè®­ç»ƒï¼ˆé»˜è®¤ï¼‰ï¼š**
```bash
python train.py
```

**å¤šGPUè®­ç»ƒï¼š**
```bash
python train.py --config config_transformer_4gpu.yaml --num_gpus 4
```

**å‘½ä»¤è¡Œè¦†ç›–é…ç½®ï¼š**
```bash
python train.py --model_type transformer --num_gpus 2
```

**å¯ç”¨è‡ªåŠ¨å…³æœºè®­ç»ƒï¼š**
```bash
# ä¿®æ”¹config.yamlä¸­ system.auto_shutdown: true
python train.py
```

### 8. åŸºå‡†æµ‹è¯•
```bash
# ä¸‹è½½æ ‡å‡†æ•°æ®é›†å’Œé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæµ‹è¯•
python test_benchmark.py

# ä»…ä¸‹è½½æ•°æ®é›†
python test_benchmark.py --datasets-only

# ä»…ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
python test_benchmark.py --models-only

# å¿«é€Ÿæµ‹è¯•è®­ç»ƒå®Œæˆçš„æ¨¡å‹
python test_after_training.py

# æµ‹è¯•æŒ‡å®šçš„æ¨¡å‹æ£€æŸ¥ç‚¹
python test_after_training.py --checkpoint checkpoints/best_model.pt
```

## ğŸ“Š æ¨¡å‹å¯¹æ¯”

| é¢„è®¾é…ç½® | æ¨¡å‹ç±»å‹ | å‚æ•°é‡ | ä¼°ç®—æ˜¾å­˜ | æ¨èGPU | é€‚ç”¨åœºæ™¯ |
|----------|----------|--------|----------|---------|----------|
| **1b_transformer** | Transformer | 1.0B | 12GB/GPU | RTX 4090Ã—1 | é€šç”¨è¯­è¨€å»ºæ¨¡ |
| **1b_mamba** | Mamba | 1.0B | 9GB/GPU | RTX 3090Ã—1 | é«˜æ•ˆé•¿åºåˆ—å¤„ç† |
| **7b_transformer** | Transformer | 7.0B | 28GB/GPU | RTX 4090Ã—4 | å¤§è§„æ¨¡è¯­è¨€å»ºæ¨¡ |
| **7b_mamba** | Mamba | 7.0B | 20GB/GPU | RTX 4090Ã—2 | é«˜æ•ˆå¤§æ¨¡å‹è®­ç»ƒ |
| **test_small** | Transformer | 50M | 2GB/GPU | ä»»æ„GPU | å¿«é€Ÿæµ‹è¯•éªŒè¯ |

### æ•°æ®é›†æ¨è

| æ¨¡å‹è§„æ¨¡ | è‹±æ–‡æ•°æ®é›† | ä¸­æ–‡æ•°æ®é›† | æ€»å¤§å° | è®­ç»ƒæ—¶é—´ä¼°ç®— |
|----------|------------|------------|--------|--------------|
| **1B** | WikiText + BookCorpus + CC-News | ä¸­æ–‡ç½‘é¡µæ–‡æœ¬ | ~80GB | 3-5å¤© |
| **7B** | OpenWebText + C4 + The Pile | ä¸­æ–‡ç½‘é¡µæ–‡æœ¬ | ~1TB+ | 2-3å‘¨ |

## âš™ï¸ é…ç½®æ–‡ä»¶

### é»˜è®¤é…ç½® (config.yaml)
```yaml
# åŸºç¡€è®¾ç½®
model_type: "mamba"  # transformer æˆ– mamba
num_gpus: 1          # GPUæ•°é‡

# æ¨¡å‹é…ç½®
model:
  d_model: 1536      # æ¨¡å‹ç»´åº¦
  n_layers: 24       # å±‚æ•°
  dropout: 0.1

# è®­ç»ƒé…ç½®
training:
  batch_size: null   # null=è‡ªåŠ¨è®¡ç®—
  max_steps: 50000
  learning_rate: 3e-4
  fp16: true
  output_dir: "./outputs"
  checkpoint_dir: "./checkpoints"

# ç³»ç»Ÿé…ç½®
system:
  auto_shutdown: false  # è®­ç»ƒå®Œæˆåè‡ªåŠ¨å…³æœº
  shutdown_delay: 60    # å…³æœºå‰ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
```

### å¤šGPUé…ç½®ç¤ºä¾‹
```yaml
model_type: "transformer"
num_gpus: 4

model:
  d_model: 1536
  n_layers: 24

training:
  batch_size: 8      # æ¯ä¸ªGPUçš„æ‰¹å¤§å°
  gradient_accumulation_steps: 2

system:
  auto_shutdown: true  # é•¿æ—¶é—´è®­ç»ƒåè‡ªåŠ¨å…³æœº
  shutdown_delay: 60
```

## ğŸ’¾ æ¨¡å‹æ–‡ä»¶ä¿å­˜

### ä¿å­˜ä½ç½®
è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹æ–‡ä»¶å°†è‡ªåŠ¨ä¿å­˜åˆ°ï¼š

```
RAG Transformer/
â”œâ”€â”€ checkpoints/           # ä¸»è¦æ¨¡å‹æ–‡ä»¶
â”‚   â”œâ”€â”€ final_model.pt    # æœ€ç»ˆè®­ç»ƒå®Œæˆçš„æ¨¡å‹
â”‚   â”œâ”€â”€ best_model.pt     # éªŒè¯é›†ä¸Šè¡¨ç°æœ€å¥½çš„æ¨¡å‹
â”‚   â””â”€â”€ checkpoint_step_*.pt  # å®šæœŸæ£€æŸ¥ç‚¹
â””â”€â”€ outputs/              # æ—¥å¿—å’Œè¾“å‡ºæ–‡ä»¶
```

### æ¨¡å‹æ–‡ä»¶è¯´æ˜

1. **final_model.pt**: è®­ç»ƒå®Œæˆæ—¶çš„æœ€ç»ˆæ¨¡å‹çŠ¶æ€
2. **best_model.pt**: éªŒè¯é›†ä¸ŠæŸå¤±æœ€ä½çš„æ¨¡å‹ï¼ˆæ¨èä½¿ç”¨ï¼‰
3. **checkpoint_step_*.pt**: æ¯5000æ­¥ä¿å­˜çš„æ£€æŸ¥ç‚¹ï¼ˆç”¨äºæ–­ç‚¹ç»­è®­ï¼‰

è¯¦ç»†è¯´æ˜è¯·å‚è€ƒï¼š[MODEL_FILES.md](MODEL_FILES.md)

### åŠ è½½æ¨¡å‹
```python
import torch
from models import create_model
from configs.base import ModelConfig

# åŠ è½½æœ€ç»ˆæ¨¡å‹
checkpoint = torch.load('checkpoints/final_model.pt')
model_config = ModelConfig(**checkpoint['config'])
model = create_model(model_config.model_type, model_config)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()
```

## ğŸ”§ é…ç½®é€‰é¡¹

### æ¨¡å‹ç±»å‹
- **transformer**: æ ‡å‡†Transformeræ¶æ„ï¼Œé€šç”¨æ€§å¥½
- **mamba**: é«˜æ•ˆMambaçŠ¶æ€ç©ºé—´æ¨¡å‹ï¼Œæ˜¾å­˜å ç”¨æ›´å°‘

### GPUé…ç½®
- `num_gpus: 1`: å•GPUè®­ç»ƒ
- `num_gpus: 2-8`: å¤šGPUå¹¶è¡Œè®­ç»ƒ

### æ‰¹å¤§å°ç­–ç•¥
- `batch_size: null`: è‡ªåŠ¨ä¼˜åŒ–ï¼ˆæ¨èï¼‰
- `batch_size: 8`: æ‰‹åŠ¨æŒ‡å®š

### è‡ªåŠ¨å…³æœº
- `auto_shutdown: false`: ç¦ç”¨è‡ªåŠ¨å…³æœºï¼ˆé»˜è®¤ï¼‰
- `auto_shutdown: true`: è®­ç»ƒå®Œæˆåè‡ªåŠ¨å…³æœº
- `shutdown_delay: 60`: å…³æœºå‰ç­‰å¾…æ—¶é—´

## ğŸ“ é¡¹ç›®ç»“æ„

```
RAG Transformer/
â”œâ”€â”€ train.py                    # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ test_multi_gpu.py           # GPUæµ‹è¯•å·¥å…·
â”œâ”€â”€ quick_test.py               # å¿«é€Ÿç¯å¢ƒæµ‹è¯•
â”œâ”€â”€ test_benchmark.py           # åŸºå‡†æµ‹è¯•è„šæœ¬
â”œâ”€â”€ test_after_training.py      # è®­ç»ƒåå¿«é€Ÿæµ‹è¯•
â”œâ”€â”€ list_datasets.py            # æ•°æ®é›†æµè§ˆå·¥å…·
â”œâ”€â”€ config.yaml                 # é»˜è®¤é…ç½®
â”œâ”€â”€ config_transformer_4gpu.yaml # å¤šGPUç¤ºä¾‹é…ç½®
â”œâ”€â”€ config_1b_transformer.yaml  # 1Bæ¨¡å‹é…ç½®
â”œâ”€â”€ config_7b_transformer.yaml  # 7Bæ¨¡å‹é…ç½®
â”œâ”€â”€ requirements.txt            # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ configs/                    # é…ç½®ç³»ç»Ÿ
â”‚   â”œâ”€â”€ base.py                 # åŸºç¡€é…ç½®ç±»
â”‚   â”œâ”€â”€ presets.py              # é¢„è®¾é…ç½®
â”‚   â”œâ”€â”€ model_presets.py        # æ¨¡å‹è§„æ¨¡é¢„è®¾
â”‚   â””â”€â”€ registry.py             # é…ç½®æ³¨å†Œ
â”œâ”€â”€ models/                     # æ¨¡å‹å®ç°
â”‚   â”œâ”€â”€ transformer.py          # Transformeræ¨¡å‹
â”‚   â”œâ”€â”€ mamba.py                # Mambaæ¨¡å‹
â”‚   â””â”€â”€ registry.py             # æ¨¡å‹æ³¨å†Œ
â”œâ”€â”€ trainers/                   # è®­ç»ƒå™¨
â”‚   â”œâ”€â”€ base.py                 # åŸºç¡€è®­ç»ƒå™¨
â”‚   â””â”€â”€ multi_gpu.py            # å¤šGPUè®­ç»ƒå™¨
â”œâ”€â”€ data/                       # æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ processor.py            # æ•°æ®å¤„ç†å™¨
â”‚   â””â”€â”€ dataset_manager.py      # æ•°æ®é›†ç®¡ç†å™¨
â”œâ”€â”€ utils/                      # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ logging.py              # æ—¥å¿—å·¥å…·
â”œâ”€â”€ test_results/               # æµ‹è¯•ç»“æœç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â””â”€â”€ data_cache/                 # æ•°æ®é›†ç¼“å­˜ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### è‡ªåŠ¨ä¼˜åŒ–
- æ ¹æ®GPUæ•°é‡è‡ªåŠ¨è°ƒæ•´æ‰¹å¤§å°
- æ™ºèƒ½æ¢¯åº¦ç´¯ç§¯è®¾ç½®
- æ··åˆç²¾åº¦è®­ç»ƒï¼ˆFP16ï¼‰

### æ˜¾å­˜ç®¡ç†
- è®­ç»ƒå‰æ˜¾å­˜éœ€æ±‚ä¼°ç®—
- è‡ªåŠ¨æ‰¹å¤§å°è®¡ç®—
- OOMé”™è¯¯é¢„é˜²

### å¤šGPUåŠ é€Ÿ
- PyTorch DistributedDataParallel (DDP)
- è‡ªåŠ¨è®¾å¤‡åˆ†é…
- é«˜æ•ˆè¿›ç¨‹é—´é€šä¿¡

## âš¡ è‡ªåŠ¨å…³æœºåŠŸèƒ½

### å¯ç”¨æ–¹å¼
1. ä¿®æ”¹ `config.yaml`ï¼š
   ```yaml
   system:
     auto_shutdown: true
     shutdown_delay: 60
   ```

2. æˆ–ä½¿ç”¨å‘½ä»¤è¡Œï¼š
   ```bash
   python train.py --no_shutdown  # ç¦ç”¨è‡ªåŠ¨å…³æœº
   ```

### è®­ç»ƒå®Œæˆæµç¨‹
1. âœ… è®­ç»ƒå®Œæˆ
2. ğŸ’¾ è‡ªåŠ¨ä¿å­˜æ¨¡å‹åˆ° `checkpoints/final_model.pt`
3. ğŸ“Š æ˜¾ç¤ºå®Œæ•´çš„æ¨¡å‹ä¿å­˜è·¯å¾„
4. â° å¼€å§‹å€’è®¡æ—¶ï¼ˆé»˜è®¤60ç§’ï¼‰
5. ğŸ’¤ æ‰§è¡Œå…³æœºå‘½ä»¤

### å–æ¶ˆå…³æœº
- **æŒ‰ Ctrl+C**: åœ¨å€’è®¡æ—¶æœŸé—´å–æ¶ˆè‡ªåŠ¨å…³æœº
- **å‘½ä»¤è¡Œ**: ä½¿ç”¨ `--no_shutdown` å‚æ•°

## ğŸ› ï¸ æ•…éšœæ’é™¤

### æ˜¾å­˜ä¸è¶³
```yaml
training:
  batch_size: 2                    # å‡å°‘æ‰¹å¤§å°
  gradient_accumulation_steps: 16  # å¢åŠ æ¢¯åº¦ç´¯ç§¯
```

### å¤šGPUé—®é¢˜
- ç¡®ä¿æ‰€æœ‰GPUå‹å·ä¸€è‡´
- æ£€æŸ¥CUDAå’ŒNCCLç‰ˆæœ¬
- éªŒè¯GPUé—´é€šä¿¡å¸¦å®½

### è®­ç»ƒé€Ÿåº¦æ…¢
- ä½¿ç”¨æ›´å¤§çš„æ‰¹å¤§å°
- å¯ç”¨FP16æ··åˆç²¾åº¦
- ä¼˜åŒ–æ•°æ®åŠ è½½å™¨workeræ•°é‡

### è‡ªåŠ¨å…³æœºå¤±è´¥
- **Windows**: ç¡®ä¿è¿è¡Œåœ¨ç®¡ç†å‘˜æƒé™
- **Linux/macOS**: ç¡®ä¿sudoæƒé™æˆ–é…ç½®å…å¯†sudo

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

### é€‚åˆ3090å•å¡çš„é…ç½®
```bash
# Mambaæ¨¡å‹ï¼Œæ˜¾å­˜å‹å¥½
python train.py --model_type mamba
```

### é€‚åˆ4090å¤šå¡çš„é…ç½®  
```bash
# Transformeræ¨¡å‹ï¼Œ4GPUå¹¶è¡Œï¼Œè®­ç»ƒå®Œæˆåè‡ªåŠ¨å…³æœº
python train.py --config config_transformer_4gpu.yaml
```

### è‡ªå®šä¹‰å¤§æ¨¡å‹è®­ç»ƒ
```yaml
model_type: "transformer"
num_gpus: 8

model:
  d_model: 2048
  n_layers: 32

training:
  batch_size: 4
  gradient_accumulation_steps: 8
  max_steps: 100000

system:
  auto_shutdown: true
  shutdown_delay: 120  # 2åˆ†é’Ÿå€’è®¡æ—¶
```

## ğŸš€ å‘½ä»¤è¡Œå‚æ•°

```bash
python train.py [OPTIONS]

é€‰é¡¹:
  --config PATH          é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)
  --model_type TEXT      æ¨¡å‹ç±»å‹ (transformer/mamba)
  --num_gpus INTEGER     GPUæ•°é‡
  --list_models          åˆ—å‡ºå¯ç”¨æ¨¡å‹
  --dry_run              éªŒè¯é…ç½®ä½†ä¸è®­ç»ƒ
  --no_shutdown          ç¦ç”¨è‡ªåŠ¨å…³æœº
  --help                 æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
```

## ğŸ” GPUæµ‹è¯•å·¥å…·

```bash
# å…¨é¢æµ‹è¯•GPUè®¾ç½®å’Œé…ç½®
python test_multi_gpu.py

# åªæ£€æŸ¥GPUä¿¡æ¯
python test_multi_gpu.py --skip_config
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
ğŸš€ RAG Transformer å¤šGPUè®­ç»ƒæµ‹è¯•
==================================================
ğŸ” GPUä¿¡æ¯æ£€æµ‹:
CUDAå¯ç”¨: True
GPUæ•°é‡: 4
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)

ğŸ’¡ ä½¿ç”¨å»ºè®®:
- å¯ä»¥ä½¿ç”¨4GPUå¹¶è¡Œè®­ç»ƒ
- ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„ num_gpus å‚æ•°
- æ‰¹å¤§å°ä¼šè‡ªåŠ¨è°ƒæ•´ä»¥é€‚åº”å¤šGPU
```

## ğŸ“ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°æ¨¡å‹
1. åœ¨ `models/` ç›®å½•ä¸‹å®ç°æ¨¡å‹ç±»
2. åœ¨ `models/registry.py` ä¸­æ³¨å†Œæ¨¡å‹
3. æ›´æ–°é…ç½®ç³»ç»Ÿæ”¯æŒæ–°æ¨¡å‹å‚æ•°

### è‡ªå®šä¹‰è®­ç»ƒé€»è¾‘
1. ç»§æ‰¿ `trainers/base.py` ä¸­çš„ `BaseTrainer`
2. é‡å†™ `train_step()` å’Œ `evaluate()` æ–¹æ³•
3. åœ¨è®­ç»ƒè„šæœ¬ä¸­ä½¿ç”¨è‡ªå®šä¹‰è®­ç»ƒå™¨

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## ï¿½ï¿½ è®¸å¯è¯

MIT License 