#!/usr/bin/env python3
"""
DeepSpeedé…ç½®è°ƒè¯•è„šæœ¬
ç”¨äºè¯Šæ–­æ‰¹æ¬¡å¤§å°é…ç½®é—®é¢˜
"""

import sys
import os

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def debug_preset_config():
    """è°ƒè¯•é¢„è®¾é…ç½®"""
    print("ğŸ” è°ƒè¯•é¢„è®¾é…ç½®...")
    
    from configs.model_presets import get_model_preset, get_training_config_for_model_size
    
    preset_id = "7b_mamba"
    num_gpus = 4
    
    print(f"\nğŸ“‹ é¢„è®¾ID: {preset_id}")
    print(f"GPUæ•°é‡: {num_gpus}")
    
    # è·å–é¢„è®¾é…ç½®
    preset_config = get_model_preset(preset_id)
    model_config = preset_config['model']
    training_config = get_training_config_for_model_size(preset_id, num_gpus)
    
    print(f"\nğŸ¤– æ¨¡å‹é…ç½®:")
    print(f"  ç±»å‹: {model_config.model_type}")
    print(f"  d_model: {model_config.d_model}")
    print(f"  n_layers: {model_config.n_layers}")
    
    print(f"\nğŸ¯ è®­ç»ƒé…ç½®:")
    print(f"  train_batch_size: {training_config.train_batch_size}")
    print(f"  gradient_accumulation_steps: {training_config.gradient_accumulation_steps}")
    print(f"  world_size: {training_config.world_size}")
    
    # è®¡ç®—é¢„æœŸçš„train_batch_size
    expected = training_config.train_batch_size * training_config.gradient_accumulation_steps * num_gpus
    print(f"\nğŸ§® æ‰¹æ¬¡å¤§å°è®¡ç®—:")
    print(f"  micro_batch_per_gpu: {training_config.train_batch_size}")
    print(f"  gradient_accumulation_steps: {training_config.gradient_accumulation_steps}")
    print(f"  world_size: {num_gpus}")
    print(f"  é¢„æœŸtrain_batch_size: {expected}")
    
    return model_config, training_config

def debug_yaml_config():
    """è°ƒè¯•YAMLé…ç½®åˆ›å»ºè¿‡ç¨‹"""
    print("\nğŸ” è°ƒè¯•YAMLé…ç½®åˆ›å»º...")
    
    from train_deepspeed import create_configs_from_yaml
    
    # æ¨¡æ‹Ÿé¢„è®¾é…ç½®åˆ›å»ºçš„yaml_config
    from configs.model_presets import get_model_preset, get_training_config_for_model_size
    
    preset_config = get_model_preset("7b_mamba")
    model_config_preset = preset_config['model']
    training_config_preset = get_training_config_for_model_size("7b_mamba", 4)
    
    yaml_config = {
        'model_type': model_config_preset.model_type,
        'num_gpus': 4,
        'model': {
            'vocab_size': model_config_preset.vocab_size,
            'max_seq_length': model_config_preset.max_seq_length,
            'd_model': model_config_preset.d_model,
            'n_layers': model_config_preset.n_layers,
            'd_state': getattr(model_config_preset, 'd_state', 16),
            'd_conv': getattr(model_config_preset, 'd_conv', 4),
            'expand': getattr(model_config_preset, 'expand', 2),
            'dropout': model_config_preset.dropout
        },
        'training': {
            'batch_size': training_config_preset.train_batch_size,
            'gradient_accumulation_steps': training_config_preset.gradient_accumulation_steps,
            'max_length': training_config_preset.max_length,
            'learning_rate': training_config_preset.learning_rate,
            'max_steps': training_config_preset.max_steps,
            'warmup_steps': training_config_preset.warmup_steps,
            'save_steps': training_config_preset.save_steps,
            'logging_steps': training_config_preset.logging_steps,
            'fp16': training_config_preset.fp16,
            'output_dir': training_config_preset.output_dir,
            'checkpoint_dir': training_config_preset.checkpoint_dir
        }
    }
    
    print(f"\nğŸ“‹ è™šæ‹ŸYAMLé…ç½®:")
    print(f"  model_type: {yaml_config['model_type']}")
    print(f"  num_gpus: {yaml_config['num_gpus']}")
    print(f"  training.batch_size: {yaml_config['training']['batch_size']}")
    print(f"  training.gradient_accumulation_steps: {yaml_config['training']['gradient_accumulation_steps']}")
    
    # é€šè¿‡create_configs_from_yamlåˆ›å»ºé…ç½®
    model_config, training_config = create_configs_from_yaml(yaml_config)
    
    print(f"\nğŸ”„ ç»è¿‡create_configs_from_yamlå:")
    print(f"  train_batch_size: {training_config.train_batch_size}")
    print(f"  gradient_accumulation_steps: {training_config.gradient_accumulation_steps}")
    print(f"  world_size: {training_config.world_size}")
    
    return model_config, training_config, yaml_config

def debug_deepspeed_config():
    """è°ƒè¯•DeepSpeedé…ç½®åˆ›å»º"""
    print("\nğŸ” è°ƒè¯•DeepSpeedé…ç½®åˆ›å»º...")
    
    from train_deepspeed import create_deepspeed_config
    
    # ä½¿ç”¨å‰é¢è°ƒè¯•å¾—åˆ°çš„é…ç½®
    model_config, training_config, yaml_config = debug_yaml_config()
    num_gpus = 4
    
    # åˆ›å»ºDeepSpeedé…ç½®
    ds_config = create_deepspeed_config(model_config, training_config, num_gpus)
    
    print(f"\nâš™ï¸ DeepSpeedé…ç½®ç»“æœ:")
    print(f"  train_batch_size: {ds_config['train_batch_size']}")
    print(f"  train_micro_batch_size_per_gpu: {ds_config['train_micro_batch_size_per_gpu']}")
    print(f"  gradient_accumulation_steps: {ds_config['gradient_accumulation_steps']}")
    
    # éªŒè¯å…¬å¼
    expected = ds_config['train_micro_batch_size_per_gpu'] * ds_config['gradient_accumulation_steps'] * num_gpus
    actual = ds_config['train_batch_size']
    
    print(f"\nâœ… å…¬å¼éªŒè¯:")
    print(f"  expected: {ds_config['train_micro_batch_size_per_gpu']} Ã— {ds_config['gradient_accumulation_steps']} Ã— {num_gpus} = {expected}")
    print(f"  actual: {actual}")
    print(f"  åŒ¹é…: {'âœ…' if expected == actual else 'âŒ'}")
    
    return ds_config

def debug_direct_yaml_load():
    """ç›´æ¥åŠ è½½YAMLæ–‡ä»¶è°ƒè¯•"""
    print("\nğŸ” è°ƒè¯•ç›´æ¥YAMLæ–‡ä»¶åŠ è½½...")
    
    from train_deepspeed import load_config, create_configs_from_yaml
    
    config_file = "config_7b_mamba.yaml"
    
    if not os.path.exists(config_file):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return
    
    # åŠ è½½åŸå§‹YAML
    yaml_config = load_config(config_file)
    yaml_config['num_gpus'] = 4  # æ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°
    
    print(f"\nğŸ“‹ åŸå§‹YAMLé…ç½®:")
    print(f"  model_type: {yaml_config.get('model_type')}")
    print(f"  num_gpus: {yaml_config.get('num_gpus')}")
    
    training_section = yaml_config.get('training', {})
    print(f"  training.batch_size: {training_section.get('batch_size')}")
    print(f"  training.gradient_accumulation_steps: {training_section.get('gradient_accumulation_steps')}")
    
    # é€šè¿‡create_configs_from_yamlå¤„ç†
    model_config, training_config = create_configs_from_yaml(yaml_config)
    
    print(f"\nğŸ”„ å¤„ç†åçš„è®­ç»ƒé…ç½®:")
    print(f"  train_batch_size: {training_config.train_batch_size}")
    print(f"  gradient_accumulation_steps: {training_config.gradient_accumulation_steps}")
    print(f"  world_size: {training_config.world_size}")
    
    # è®¡ç®—é¢„æœŸçš„train_batch_size
    expected = training_config.train_batch_size * training_config.gradient_accumulation_steps * 4
    print(f"\nğŸ§® æ‰¹æ¬¡å¤§å°è®¡ç®—:")
    print(f"  {training_config.train_batch_size} Ã— {training_config.gradient_accumulation_steps} Ã— 4 = {expected}")
    
    return model_config, training_config

def main():
    print("ğŸ› DeepSpeedé…ç½®è°ƒè¯•å·¥å…·")
    print("=" * 60)
    
    try:
        # 1. è°ƒè¯•é¢„è®¾é…ç½®
        debug_preset_config()
        
        # 2. è°ƒè¯•YAMLé…ç½®åˆ›å»º
        debug_yaml_config()
        
        # 3. è°ƒè¯•DeepSpeedé…ç½®
        debug_deepspeed_config()
        
        # 4. è°ƒè¯•ç›´æ¥YAMLåŠ è½½
        debug_direct_yaml_load()
        
        print("\nğŸ¯ é—®é¢˜è¯Šæ–­å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ è°ƒè¯•è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 