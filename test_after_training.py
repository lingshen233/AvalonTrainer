#!/usr/bin/env python3
"""
è®­ç»ƒåå¿«é€Ÿæµ‹è¯•è„šæœ¬
æµ‹è¯•åˆšè®­ç»ƒå®Œæˆçš„æ¨¡å‹
"""

import os
import sys
import argparse
import torch
from configs.base import ModelConfig
from models import create_model

def remove_module_prefix(state_dict):
    """ç§»é™¤DDPæ¨¡å‹çš„module.å‰ç¼€"""
    new_state_dict = {}
    for k, v in state_dict.items():
        if k.startswith('module.'):
            new_state_dict[k[7:]] = v  # ç§»é™¤'module.'å‰ç¼€
        else:
            new_state_dict[k] = v
    return new_state_dict

def test_model(checkpoint_path):
    """æµ‹è¯•æ¨¡å‹"""
    print("============================================================")
    print(f"ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å‹: {checkpoint_path}")
    
    if not os.path.exists(checkpoint_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        return False
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
    except Exception as e:
        print(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
        return False
    
    # è·å–é…ç½®
    if 'config' not in checkpoint:
        print("âŒ æ£€æŸ¥ç‚¹ä¸­ç¼ºå°‘é…ç½®ä¿¡æ¯")
        return False
    
    config_dict = checkpoint['config']
    print(f"ğŸ“‹ æ¨¡å‹é…ç½®: {config_dict['model_type']}")
    
    # åˆ›å»ºæ¨¡å‹é…ç½®
    model_config = ModelConfig(**config_dict)
    
    # åˆ›å»ºæ¨¡å‹
    print("ğŸ”§ åˆ›å»ºæ¨¡å‹...")
    try:
        model = create_model(model_config.model_type, model_config)
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ¨¡å‹å¤±è´¥: {e}")
        return False
    
    # å¤„ç†DDPæ¨¡å‹çš„state_dict
    state_dict = checkpoint['model_state_dict']
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯DDPæ¨¡å‹ï¼ˆé”®åæœ‰module.å‰ç¼€ï¼‰
    has_module_prefix = any(k.startswith('module.') for k in state_dict.keys())
    if has_module_prefix:
        print("ğŸ”„ æ£€æµ‹åˆ°DDPæ¨¡å‹ï¼Œç§»é™¤module.å‰ç¼€...")
        state_dict = remove_module_prefix(state_dict)
    
    # åŠ è½½æ¨¡å‹å‚æ•°
    print("ğŸ“¥ åŠ è½½æ¨¡å‹å‚æ•°...")
    try:
        model.load_state_dict(state_dict, strict=True)
        print("âœ… æ¨¡å‹å‚æ•°åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å‚æ•°å¤±è´¥: {e}")
        return False
    
    # è®¾ç½®è¯„ä¼°æ¨¡å¼
    model.eval()
    
    # è·å–è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è®¡ç®—æ¨¡å‹å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ“Š æ¨¡å‹å‚æ•°é‡: {total_params:,} ({total_params/1e6:.1f}M)")
    
    # ç®€å•çš„å‰å‘ä¼ æ’­æµ‹è¯•
    print("ğŸ§ª æ‰§è¡Œå‰å‘ä¼ æ’­æµ‹è¯•...")
    try:
        batch_size = 2
        seq_length = 128
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_input = torch.randint(0, model_config.vocab_size, (batch_size, seq_length)).to(device)
        
        with torch.no_grad():
            outputs = model(test_input)
        
        if hasattr(outputs, 'logits'):
            output_shape = outputs.logits.shape
        else:
            output_shape = outputs.shape
        
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   è¾“å…¥å½¢çŠ¶: {test_input.shape}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {output_shape}")
        
        # ç®€å•çš„æ–‡æœ¬ç”Ÿæˆæµ‹è¯•
        print("ğŸ“ æ‰§è¡Œæ–‡æœ¬ç”Ÿæˆæµ‹è¯•...")
        prompt = torch.randint(0, 1000, (1, 10)).to(device)  # ç®€å•çš„æç¤º
        
        with torch.no_grad():
            for i in range(5):  # ç”Ÿæˆ5ä¸ªtoken
                outputs = model(prompt)
                if hasattr(outputs, 'logits'):
                    logits = outputs.logits
                else:
                    logits = outputs
                
                next_token = torch.argmax(logits[:, -1, :], dim=-1, keepdim=True)
                prompt = torch.cat([prompt, next_token], dim=1)
        
        print(f"âœ… æ–‡æœ¬ç”Ÿæˆæµ‹è¯•æˆåŠŸ")
        print(f"   ç”Ÿæˆåºåˆ—é•¿åº¦: {prompt.shape[1]}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description="è®­ç»ƒåæ¨¡å‹æµ‹è¯•")
    parser.add_argument("--checkpoint", type=str, default="checkpoints/final_model.pt", 
                       help="æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„")
    
    args = parser.parse_args()
    
    success = test_model(args.checkpoint)
    
    success_count = 1 if success else 0
    print(f"\nğŸ¯ æµ‹è¯•å®Œæˆ: {success_count}/1 æˆåŠŸ")
    
    if success:
        print("âœ… æ¨¡å‹è¿è¡Œæ­£å¸¸ï¼")
        print("ğŸ’¡ ä¸‹ä¸€æ­¥å¯ä»¥:")
        print("   1. è¿è¡Œå®Œæ•´åŸºå‡†æµ‹è¯•: python test_benchmark.py")
        print("   2. å°è¯•è®­ç»ƒæ›´å¤§æ¨¡å‹: python train.py --preset 1b_transformer")
        print("   3. è¿›è¡Œå®é™…æ¨ç†ä»»åŠ¡")
    else:
        print("âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")

if __name__ == "__main__":
    main() 