#!/usr/bin/env python3
"""
å®æ—¶GPU TFLOPæ€§èƒ½æ£€æµ‹å™¨
æ£€æµ‹å½“å‰ç³»ç»ŸGPUå¹¶è¿è¡Œå®é™…åŸºå‡†æµ‹è¯•è®¡ç®—TFLOPæ€§èƒ½
"""

import os
import sys
import time
import json
import argparse
import subprocess
import platform
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import threading

# GPUæ£€æµ‹ç›¸å…³å¯¼å…¥
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    import pynvml
    NVIDIA_ML_AVAILABLE = True
except ImportError:
    NVIDIA_ML_AVAILABLE = False

try:
    import GPUtil
    GPUTIL_AVAILABLE = True
except ImportError:
    GPUTIL_AVAILABLE = False

@dataclass
class RealTimeGPUInfo:
    """å®æ—¶GPUä¿¡æ¯"""
    device_id: int
    name: str
    total_memory: int  # å­—èŠ‚
    free_memory: int   # å­—èŠ‚
    used_memory: int   # å­—èŠ‚
    temperature: Optional[int]
    power_usage: Optional[float]
    utilization: Optional[int]
    clock_graphics: Optional[int]  # MHz
    clock_memory: Optional[int]    # MHz
    cuda_cores: Optional[int]
    compute_capability: Optional[Tuple[int, int]]
    driver_version: Optional[str]
    cuda_version: Optional[str]

class RealTimeGPUDetector:
    """å®æ—¶GPUæ£€æµ‹å™¨"""
    
    def __init__(self):
        self.torch_available = TORCH_AVAILABLE
        self.nvidia_ml_available = NVIDIA_ML_AVAILABLE
        self.gputil_available = GPUTIL_AVAILABLE
        
        # åˆå§‹åŒ–NVIDIA ML
        if self.nvidia_ml_available:
            try:
                pynvml.nvmlInit()
                self.nvidia_ml_initialized = True
            except:
                self.nvidia_ml_initialized = False
        else:
            self.nvidia_ml_initialized = False
    
    def get_nvidia_smi_info(self) -> Dict:
        """é€šè¿‡nvidia-smiè·å–GPUä¿¡æ¯"""
        try:
            result = subprocess.run([
                'nvidia-smi', 
                '--query-gpu=index,name,memory.total,memory.free,memory.used,temperature.gpu,power.draw,utilization.gpu,clocks.current.graphics,clocks.current.memory,driver_version',
                '--format=csv,noheader,nounits'
            ], capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0:
                gpus = []
                for line in result.stdout.strip().split('\n'):
                    if line.strip():
                        parts = [p.strip() for p in line.split(',')]
                        if len(parts) >= 11:
                            gpus.append({
                                'index': int(parts[0]),
                                'name': parts[1],
                                'memory_total': int(parts[2]) if parts[2] != '[Not Supported]' else 0,
                                'memory_free': int(parts[3]) if parts[3] != '[Not Supported]' else 0,
                                'memory_used': int(parts[4]) if parts[4] != '[Not Supported]' else 0,
                                'temperature': int(parts[5]) if parts[5] != '[Not Supported]' else None,
                                'power_draw': float(parts[6]) if parts[6] != '[Not Supported]' else None,
                                'utilization': int(parts[7]) if parts[7] != '[Not Supported]' else None,
                                'clock_graphics': int(parts[8]) if parts[8] != '[Not Supported]' else None,
                                'clock_memory': int(parts[9]) if parts[9] != '[Not Supported]' else None,
                                'driver_version': parts[10] if parts[10] != '[Not Supported]' else None
                            })
                return {'gpus': gpus, 'method': 'nvidia-smi'}
        except Exception as e:
            print(f"nvidia-smiæ£€æµ‹å¤±è´¥: {e}")
        
        return {'gpus': [], 'method': 'nvidia-smi'}
    
    def get_torch_gpu_info(self) -> Dict:
        """é€šè¿‡PyTorchè·å–GPUä¿¡æ¯"""
        if not self.torch_available:
            return {'gpus': [], 'method': 'torch'}
        
        try:
            if not torch.cuda.is_available():
                return {'gpus': [], 'method': 'torch'}
            
            gpus = []
            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                device = torch.device(f'cuda:{i}')
                
                # è·å–æ˜¾å­˜ä¿¡æ¯
                torch.cuda.set_device(i)
                memory_total = torch.cuda.get_device_properties(i).total_memory
                memory_free = torch.cuda.memory_reserved(i)
                memory_used = torch.cuda.memory_allocated(i)
                
                gpus.append({
                    'index': i,
                    'name': props.name,
                    'memory_total': memory_total // (1024**2),  # MB
                    'memory_free': (memory_total - memory_used) // (1024**2),
                    'memory_used': memory_used // (1024**2),
                    'compute_capability': (props.major, props.minor),
                    'multiprocessor_count': props.multi_processor_count,
                    'max_threads_per_multiprocessor': props.max_threads_per_multi_processor,
                    'max_threads_per_block': props.max_threads_per_block,
                    'cuda_version': torch.version.cuda
                })
            
            return {'gpus': gpus, 'method': 'torch'}
        except Exception as e:
            print(f"PyTorch GPUæ£€æµ‹å¤±è´¥: {e}")
            return {'gpus': [], 'method': 'torch'}
    
    def get_pynvml_info(self) -> Dict:
        """é€šè¿‡pynvmlè·å–GPUä¿¡æ¯"""
        if not self.nvidia_ml_initialized:
            return {'gpus': [], 'method': 'pynvml'}
        
        try:
            device_count = pynvml.nvmlDeviceGetCount()
            gpus = []
            
            for i in range(device_count):
                handle = pynvml.nvmlDeviceGetHandleByIndex(i)
                
                # åŸºæœ¬ä¿¡æ¯
                name = pynvml.nvmlDeviceGetName(handle).decode('utf-8')
                
                # æ˜¾å­˜ä¿¡æ¯
                memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                
                # æ¸©åº¦
                try:
                    temperature = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)
                except:
                    temperature = None
                
                # åŠŸè€—
                try:
                    power_usage = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # mW to W
                except:
                    power_usage = None
                
                # åˆ©ç”¨ç‡
                try:
                    utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)
                    gpu_util = utilization.gpu
                except:
                    gpu_util = None
                
                # æ—¶é’Ÿé¢‘ç‡
                try:
                    clock_graphics = pynvml.nvmlDeviceGetClockInfo(handle, pynvml.NVML_CLOCK_GRAPHICS)
                    clock_memory = pynvml.nvmlDeviceGetClockInfo(handle, pynvml.NVML_CLOCK_MEM)
                except:
                    clock_graphics = clock_memory = None
                
                gpus.append({
                    'index': i,
                    'name': name,
                    'memory_total': memory_info.total // (1024**2),  # MB
                    'memory_free': memory_info.free // (1024**2),
                    'memory_used': memory_info.used // (1024**2),
                    'temperature': temperature,
                    'power_usage': power_usage,
                    'utilization': gpu_util,
                    'clock_graphics': clock_graphics,
                    'clock_memory': clock_memory
                })
            
            return {'gpus': gpus, 'method': 'pynvml'}
        except Exception as e:
            print(f"pynvml GPUæ£€æµ‹å¤±è´¥: {e}")
            return {'gpus': [], 'method': 'pynvml'}
    
    def detect_gpus(self) -> List[RealTimeGPUInfo]:
        """ç»¼åˆæ£€æµ‹GPUä¿¡æ¯"""
        print("ğŸ” æ£€æµ‹å½“å‰ç³»ç»ŸGPU...")
        
        # ä¼˜å…ˆä½¿ç”¨nvidia-smi
        nvidia_smi_info = self.get_nvidia_smi_info()
        torch_info = self.get_torch_gpu_info()
        pynvml_info = self.get_pynvml_info()
        
        # åˆå¹¶ä¿¡æ¯
        gpu_list = []
        
        if nvidia_smi_info['gpus']:
            print(f"âœ… é€šè¿‡nvidia-smiæ£€æµ‹åˆ° {len(nvidia_smi_info['gpus'])} ä¸ªGPU")
            
            for smi_gpu in nvidia_smi_info['gpus']:
                # æŸ¥æ‰¾å¯¹åº”çš„torchä¿¡æ¯
                torch_gpu = None
                if torch_info['gpus']:
                    for tg in torch_info['gpus']:
                        if tg['index'] == smi_gpu['index']:
                            torch_gpu = tg
                            break
                
                # æŸ¥æ‰¾å¯¹åº”çš„pynvmlä¿¡æ¯
                pynvml_gpu = None
                if pynvml_info['gpus']:
                    for pg in pynvml_info['gpus']:
                        if pg['index'] == smi_gpu['index']:
                            pynvml_gpu = pg
                            break
                
                # åˆå¹¶ä¿¡æ¯
                gpu_info = RealTimeGPUInfo(
                    device_id=smi_gpu['index'],
                    name=smi_gpu['name'],
                    total_memory=smi_gpu['memory_total'] * 1024 * 1024,  # MB to bytes
                    free_memory=smi_gpu['memory_free'] * 1024 * 1024,
                    used_memory=smi_gpu['memory_used'] * 1024 * 1024,
                    temperature=smi_gpu['temperature'],
                    power_usage=smi_gpu['power_draw'],
                    utilization=smi_gpu['utilization'],
                    clock_graphics=smi_gpu['clock_graphics'],
                    clock_memory=smi_gpu['clock_memory'],
                    cuda_cores=self._estimate_cuda_cores(smi_gpu['name']),
                    compute_capability=torch_gpu['compute_capability'] if torch_gpu else None,
                    driver_version=smi_gpu['driver_version'],
                    cuda_version=torch_gpu['cuda_version'] if torch_gpu else None
                )
                
                gpu_list.append(gpu_info)
        
        elif torch_info['gpus']:
            print(f"âœ… é€šè¿‡PyTorchæ£€æµ‹åˆ° {len(torch_info['gpus'])} ä¸ªGPU")
            
            for torch_gpu in torch_info['gpus']:
                gpu_info = RealTimeGPUInfo(
                    device_id=torch_gpu['index'],
                    name=torch_gpu['name'],
                    total_memory=torch_gpu['memory_total'] * 1024 * 1024,
                    free_memory=torch_gpu['memory_free'] * 1024 * 1024,
                    used_memory=torch_gpu['memory_used'] * 1024 * 1024,
                    temperature=None,
                    power_usage=None,
                    utilization=None,
                    clock_graphics=None,
                    clock_memory=None,
                    cuda_cores=self._estimate_cuda_cores(torch_gpu['name']),
                    compute_capability=torch_gpu['compute_capability'],
                    driver_version=None,
                    cuda_version=torch_gpu['cuda_version']
                )
                gpu_list.append(gpu_info)
        
        else:
            print("âŒ æœªæ£€æµ‹åˆ°NVIDIA GPU")
        
        return gpu_list
    
    def _estimate_cuda_cores(self, gpu_name: str) -> Optional[int]:
        """æ ¹æ®GPUåç§°ä¼°ç®—CUDAæ ¸å¿ƒæ•°"""
        core_mapping = {
            'RTX 4090': 16384,
            'RTX 4080': 9728,
            'RTX 4070': 5888,
            'RTX 3090': 10496,
            'RTX 3080': 8704,
            'RTX 3070': 5888,
            'A100': 6912,
            'V100': 5120,
            'RTX A6000': 10752,
            'RTX A5000': 8192,
            'GTX 1080': 2560,
            'GTX 1070': 1920,
            'GTX 1060': 1280,
        }
        
        for key, cores in core_mapping.items():
            if key in gpu_name:
                return cores
        
        return None

class RealTimeTFLOPBenchmark:
    """å®æ—¶TFLOPæ€§èƒ½æµ‹è¯•"""
    
    def __init__(self):
        self.torch_available = TORCH_AVAILABLE
    
    def run_fp32_benchmark(self, device_id: int, duration: int = 5) -> float:
        """è¿è¡ŒFP32æ€§èƒ½æµ‹è¯•"""
        if not self.torch_available:
            return 0.0
        
        try:
            device = torch.device(f'cuda:{device_id}')
            torch.cuda.set_device(device_id)
            
            # é¢„çƒ­
            print(f"ğŸ”¥ GPU {device_id} FP32é¢„çƒ­ä¸­...")
            for _ in range(10):
                a = torch.randn(1024, 1024, device=device)
                b = torch.randn(1024, 1024, device=device)
                c = torch.matmul(a, b)
                torch.cuda.synchronize()
            
            # å®é™…æµ‹è¯•
            print(f"âš¡ GPU {device_id} FP32æ€§èƒ½æµ‹è¯•ä¸­ ({duration}ç§’)...")
            
            matrix_size = 2048  # å¯æ ¹æ®æ˜¾å­˜è°ƒæ•´
            operations = 0
            
            torch.cuda.synchronize()
            start_time = time.time()
            end_time = start_time + duration
            
            while time.time() < end_time:
                a = torch.randn(matrix_size, matrix_size, device=device, dtype=torch.float32)
                b = torch.randn(matrix_size, matrix_size, device=device, dtype=torch.float32)
                c = torch.matmul(a, b)
                torch.cuda.synchronize()
                
                # çŸ©é˜µä¹˜æ³•è¿ç®—é‡: 2 * n^3 (n^3æ¬¡ä¹˜æ³• + n^3æ¬¡åŠ æ³•)
                operations += 2 * (matrix_size ** 3)
            
            actual_duration = time.time() - start_time
            tflops = operations / actual_duration / 1e12
            
            return tflops
            
        except Exception as e:
            print(f"FP32æµ‹è¯•å¤±è´¥: {e}")
            return 0.0
    
    def run_fp16_benchmark(self, device_id: int, duration: int = 5) -> float:
        """è¿è¡ŒFP16æ€§èƒ½æµ‹è¯•"""
        if not self.torch_available:
            return 0.0
        
        try:
            device = torch.device(f'cuda:{device_id}')
            torch.cuda.set_device(device_id)
            
            # æ£€æŸ¥FP16æ”¯æŒ
            if not torch.cuda.get_device_capability(device_id)[0] >= 6:
                print(f"GPU {device_id} ä¸æ”¯æŒFP16")
                return 0.0
            
            # é¢„çƒ­
            print(f"ğŸ”¥ GPU {device_id} FP16é¢„çƒ­ä¸­...")
            for _ in range(10):
                a = torch.randn(1024, 1024, device=device, dtype=torch.float16)
                b = torch.randn(1024, 1024, device=device, dtype=torch.float16)
                c = torch.matmul(a, b)
                torch.cuda.synchronize()
            
            # å®é™…æµ‹è¯•
            print(f"âš¡ GPU {device_id} FP16æ€§èƒ½æµ‹è¯•ä¸­ ({duration}ç§’)...")
            
            matrix_size = 4096  # FP16å¯ä»¥ä½¿ç”¨æ›´å¤§çŸ©é˜µ
            operations = 0
            
            torch.cuda.synchronize()
            start_time = time.time()
            end_time = start_time + duration
            
            while time.time() < end_time:
                a = torch.randn(matrix_size, matrix_size, device=device, dtype=torch.float16)
                b = torch.randn(matrix_size, matrix_size, device=device, dtype=torch.float16)
                c = torch.matmul(a, b)
                torch.cuda.synchronize()
                
                operations += 2 * (matrix_size ** 3)
            
            actual_duration = time.time() - start_time
            tflops = operations / actual_duration / 1e12
            
            return tflops
            
        except Exception as e:
            print(f"FP16æµ‹è¯•å¤±è´¥: {e}")
            return 0.0
    
    def run_tensor_benchmark(self, device_id: int, duration: int = 5) -> float:
        """è¿è¡ŒTensor Coreæ€§èƒ½æµ‹è¯•"""
        if not self.torch_available:
            return 0.0
        
        try:
            device = torch.device(f'cuda:{device_id}')
            torch.cuda.set_device(device_id)
            
            # æ£€æŸ¥Tensor Coreæ”¯æŒ
            major, minor = torch.cuda.get_device_capability(device_id)
            if major < 7:  # Voltaæ¶æ„å¼€å§‹æ”¯æŒTensor Core
                print(f"GPU {device_id} ä¸æ”¯æŒTensor Core")
                return 0.0
            
            # é¢„çƒ­
            print(f"ğŸ”¥ GPU {device_id} Tensor Coreé¢„çƒ­ä¸­...")
            for _ in range(10):
                a = torch.randn(512, 512, device=device, dtype=torch.float16)
                b = torch.randn(512, 512, device=device, dtype=torch.float16)
                with torch.cuda.amp.autocast():
                    c = torch.matmul(a, b)
                torch.cuda.synchronize()
            
            # å®é™…æµ‹è¯•
            print(f"âš¡ GPU {device_id} Tensor Coreæ€§èƒ½æµ‹è¯•ä¸­ ({duration}ç§’)...")
            
            matrix_size = 8192  # Tensor Coreä¼˜åŒ–çš„çŸ©é˜µå¤§å°
            operations = 0
            
            torch.cuda.synchronize()
            start_time = time.time()
            end_time = start_time + duration
            
            while time.time() < end_time:
                a = torch.randn(matrix_size, matrix_size, device=device, dtype=torch.float16)
                b = torch.randn(matrix_size, matrix_size, device=device, dtype=torch.float16)
                
                with torch.cuda.amp.autocast():
                    c = torch.matmul(a, b)
                torch.cuda.synchronize()
                
                operations += 2 * (matrix_size ** 3)
            
            actual_duration = time.time() - start_time
            tflops = operations / actual_duration / 1e12
            
            return tflops
            
        except Exception as e:
            print(f"Tensor Coreæµ‹è¯•å¤±è´¥: {e}")
            return 0.0

def print_gpu_status(gpu_info: RealTimeGPUInfo):
    """æ‰“å°GPUçŠ¶æ€ä¿¡æ¯"""
    print(f"\nğŸ® GPU {gpu_info.device_id}: {gpu_info.name}")
    print("=" * 80)
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"æ˜¾å­˜: {gpu_info.total_memory // (1024**3):.1f} GB "
          f"(ä½¿ç”¨: {gpu_info.used_memory // (1024**3):.1f} GB, "
          f"ç©ºé—²: {gpu_info.free_memory // (1024**3):.1f} GB)")
    
    if gpu_info.temperature:
        print(f"æ¸©åº¦: {gpu_info.temperature}Â°C")
    
    if gpu_info.power_usage:
        print(f"åŠŸè€—: {gpu_info.power_usage:.1f} W")
    
    if gpu_info.utilization is not None:
        print(f"åˆ©ç”¨ç‡: {gpu_info.utilization}%")
    
    if gpu_info.clock_graphics:
        print(f"æ ¸å¿ƒé¢‘ç‡: {gpu_info.clock_graphics} MHz")
    
    if gpu_info.clock_memory:
        print(f"æ˜¾å­˜é¢‘ç‡: {gpu_info.clock_memory} MHz")
    
    if gpu_info.cuda_cores:
        print(f"CUDAæ ¸å¿ƒ: {gpu_info.cuda_cores:,}")
    
    if gpu_info.compute_capability:
        print(f"è®¡ç®—èƒ½åŠ›: {gpu_info.compute_capability[0]}.{gpu_info.compute_capability[1]}")
    
    if gpu_info.driver_version:
        print(f"é©±åŠ¨ç‰ˆæœ¬: {gpu_info.driver_version}")
    
    if gpu_info.cuda_version:
        print(f"CUDAç‰ˆæœ¬: {gpu_info.cuda_version}")

def print_benchmark_results(gpu_info: RealTimeGPUInfo, fp32_tflops: float, fp16_tflops: float, tensor_tflops: float):
    """æ‰“å°æ€§èƒ½æµ‹è¯•ç»“æœ"""
    print(f"\nğŸ“Š GPU {gpu_info.device_id} æ€§èƒ½æµ‹è¯•ç»“æœ:")
    print("-" * 60)
    print(f"FP32æ€§èƒ½:      {fp32_tflops:.2f} TFLOPS")
    print(f"FP16æ€§èƒ½:      {fp16_tflops:.2f} TFLOPS")
    print(f"Tensoræ€§èƒ½:    {tensor_tflops:.2f} TFLOPS")
    
    # æ•ˆç‡è®¡ç®—
    if gpu_info.power_usage and fp32_tflops > 0:
        efficiency = fp32_tflops / gpu_info.power_usage
        print(f"FP32æ•ˆç‡:      {efficiency:.3f} TFLOPS/W")
    
    # æ˜¾å­˜æ•ˆç‡
    if fp32_tflops > 0:
        memory_efficiency = (gpu_info.total_memory // (1024**3)) / fp32_tflops
        print(f"æ˜¾å­˜æ•ˆç‡:      {memory_efficiency:.1f} GB/TFLOP")

def main():
    parser = argparse.ArgumentParser(description="å®æ—¶GPU TFLOPæ€§èƒ½æ£€æµ‹å™¨")
    parser.add_argument("--list", action="store_true", help="ä»…åˆ—å‡ºGPUä¿¡æ¯")
    parser.add_argument("--benchmark", action="store_true", help="è¿è¡Œæ€§èƒ½æµ‹è¯•")
    parser.add_argument("--duration", type=int, default=5, help="æ¯é¡¹æµ‹è¯•æŒç»­æ—¶é—´(ç§’)")
    parser.add_argument("--device", type=int, help="æŒ‡å®šæµ‹è¯•çš„GPUè®¾å¤‡ID")
    parser.add_argument("--precision", choices=["fp32", "fp16", "tensor", "all"], 
                       default="all", help="æµ‹è¯•ç²¾åº¦")
    parser.add_argument("--export", type=str, help="å¯¼å‡ºç»“æœåˆ°JSONæ–‡ä»¶")
    parser.add_argument("--monitor", action="store_true", help="å®æ—¶ç›‘æ§æ¨¡å¼")
    
    args = parser.parse_args()
    
    print("ğŸš€ å®æ—¶GPU TFLOPæ€§èƒ½æ£€æµ‹å™¨")
    print("=" * 50)
    
    # æ£€æŸ¥ä¾èµ–
    print("\nğŸ“‹ ä¾èµ–æ£€æŸ¥:")
    print(f"PyTorch: {'âœ…' if TORCH_AVAILABLE else 'âŒ'}")
    print(f"pynvml: {'âœ…' if NVIDIA_ML_AVAILABLE else 'âŒ'}")
    print(f"GPUtil: {'âœ…' if GPUTIL_AVAILABLE else 'âŒ'}")
    
    if not TORCH_AVAILABLE:
        print("\nâš ï¸ è­¦å‘Š: æœªå®‰è£…PyTorchï¼Œæ— æ³•è¿è¡Œæ€§èƒ½æµ‹è¯•")
        print("å®‰è£…å‘½ä»¤: pip install torch")
    
    # æ£€æµ‹GPU
    detector = RealTimeGPUDetector()
    gpus = detector.detect_gpus()
    
    if not gpus:
        print("\nâŒ æœªæ£€æµ‹åˆ°GPUæˆ–GPUä¸å¯ç”¨")
        sys.exit(1)
    
    print(f"\nâœ… æ£€æµ‹åˆ° {len(gpus)} ä¸ªGPU")
    
    # æ˜¾ç¤ºGPUä¿¡æ¯
    for gpu in gpus:
        print_gpu_status(gpu)
    
    if args.list:
        return
    
    # è¿è¡Œæ€§èƒ½æµ‹è¯•
    if args.benchmark and TORCH_AVAILABLE:
        benchmark = RealTimeTFLOPBenchmark()
        results = {}
        
        target_gpus = [gpus[args.device]] if args.device is not None else gpus
        
        for gpu in target_gpus:
            print(f"\nğŸƒ å¼€å§‹æµ‹è¯•GPU {gpu.device_id}: {gpu.name}")
            
            fp32_tflops = fp16_tflops = tensor_tflops = 0.0
            
            if args.precision in ["fp32", "all"]:
                fp32_tflops = benchmark.run_fp32_benchmark(gpu.device_id, args.duration)
            
            if args.precision in ["fp16", "all"]:
                fp16_tflops = benchmark.run_fp16_benchmark(gpu.device_id, args.duration)
            
            if args.precision in ["tensor", "all"]:
                tensor_tflops = benchmark.run_tensor_benchmark(gpu.device_id, args.duration)
            
            print_benchmark_results(gpu, fp32_tflops, fp16_tflops, tensor_tflops)
            
            results[f"gpu_{gpu.device_id}"] = {
                "name": gpu.name,
                "fp32_tflops": fp32_tflops,
                "fp16_tflops": fp16_tflops,
                "tensor_tflops": tensor_tflops,
                "memory_gb": gpu.total_memory // (1024**3),
                "power_usage": gpu.power_usage,
                "temperature": gpu.temperature
            }
        
        # å¯¼å‡ºç»“æœ
        if args.export:
            with open(args.export, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ“ ç»“æœå·²å¯¼å‡ºåˆ°: {args.export}")
    
    # å®æ—¶ç›‘æ§æ¨¡å¼
    if args.monitor:
        print("\nğŸ”„ è¿›å…¥å®æ—¶ç›‘æ§æ¨¡å¼ (Ctrl+Cé€€å‡º)")
        try:
            while True:
                os.system('clear' if os.name == 'posix' else 'cls')
                print("ğŸ”„ å®æ—¶GPUçŠ¶æ€ç›‘æ§")
                print("=" * 50)
                
                # é‡æ–°æ£€æµ‹GPUçŠ¶æ€
                gpus = detector.detect_gpus()
                for gpu in gpus:
                    print_gpu_status(gpu)
                
                time.sleep(2)
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç›‘æ§ç»“æŸ")

if __name__ == "__main__":
    main() 