#!/bin/bash

# 6GPUæ˜¾å­˜å®‰å…¨å¯åŠ¨è„šæœ¬
# ä½¿ç”¨æé™ä¼˜åŒ–é…ç½®é¿å…æ˜¾å­˜æº¢å‡º

echo "ğŸš€ å¯åŠ¨6GPUæ˜¾å­˜å®‰å…¨è®­ç»ƒ"
echo "=========================="

# è®¾ç½®ç¯å¢ƒå˜é‡ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export CUDA_LAUNCH_BLOCKING=0

# æ¸…ç†GPUæ˜¾å­˜
echo "ğŸ§¹ æ¸…ç†GPUæ˜¾å­˜..."
python -c "
import torch
if torch.cuda.is_available():
    for i in range(torch.cuda.device_count()):
        torch.cuda.set_device(i)
        torch.cuda.empty_cache()
    print(f'âœ… å·²æ¸…ç† {torch.cuda.device_count()} å¼ GPUæ˜¾å­˜')
else:
    print('âŒ CUDAä¸å¯ç”¨')
"

# æ£€æŸ¥æ˜¾å­˜çŠ¶æ€
echo "ğŸ” æ£€æŸ¥æ˜¾å­˜çŠ¶æ€..."
python diagnose_memory_issue.py --model_size 7

echo ""
echo "ğŸš€ ä½¿ç”¨6GPUæé™ä¼˜åŒ–é…ç½®å¯åŠ¨è®­ç»ƒ..."
echo "é…ç½®æ–‡ä»¶: deepspeed_6gpu.json"
echo "ZeROé˜¶æ®µ: 3 (å‚æ•°åˆ†ç‰‡)"
echo "CPUå¸è½½: ä¼˜åŒ–å™¨+å‚æ•°"
echo "micro_batch_per_gpu: 1"
echo "gradient_accumulation_steps: 8"
echo "æœ‰æ•ˆæ‰¹å¤§å°: 48"
echo ""

# å¯åŠ¨è®­ç»ƒ
deepspeed --num_gpus=6 train_deepspeed.py \
    --preset 7b_mamba \
    --deepspeed_config deepspeed_6gpu.json \
    --num_gpus 6

echo "âœ… è®­ç»ƒå®Œæˆï¼" 