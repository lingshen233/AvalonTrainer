#!/bin/bash

echo "ğŸš€ å•å¡A800-80GBè®­ç»ƒå¯åŠ¨è„šæœ¬"
echo "================================================"

# æ£€æŸ¥æ˜¯å¦ä¸ºA800/A100
GPU_NAME=$(nvidia-smi --query-gpu=gpu_name --format=csv,noheader,nounits | head -n1)
echo "ğŸ® æ£€æµ‹åˆ°GPU: $GPU_NAME"

if [[ ! "$GPU_NAME" =~ "A800" ]] && [[ ! "$GPU_NAME" =~ "A100" ]]; then
    echo "âš ï¸  è­¦å‘Š: æ£€æµ‹åˆ°çš„GPUä¸æ˜¯A800/A100ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´é…ç½®"
fi

# è®¾ç½®å†…å­˜ä¼˜åŒ–ç¯å¢ƒå˜é‡ï¼ˆç›¸å¯¹æ¸©å’Œï¼Œåˆ©ç”¨å¤§æ˜¾å­˜ä¼˜åŠ¿ï¼‰
export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"
export CUDA_LAUNCH_BLOCKING=0

# è®¾ç½®CPUä½¿ç”¨
export OMP_NUM_THREADS=8
export MKL_NUM_THREADS=8

# æ¸…ç†GPUç¼“å­˜
python -c "import torch; torch.cuda.empty_cache(); print('âœ… GPUç¼“å­˜å·²æ¸…ç†')"

echo "ğŸ“Š æ£€æŸ¥GPUçŠ¶æ€..."
nvidia-smi --query-gpu=index,name,memory.used,memory.total --format=csv,noheader,nounits

echo ""
echo "ğŸ”§ ä½¿ç”¨å•å¡A800-80Gä¼˜åŒ–é…ç½®..."
echo "  - Batch Size: 16 (æ¯GPU 4ä¸ªæ ·æœ¬)"
echo "  - ZeRO-2 + ä¼˜åŒ–å™¨CPUå¸è½½"
echo "  - é€‚åº¦æ¿€æ´»æ£€æŸ¥ç‚¹"
echo "  - FP16æ ‡å‡†è®¾ç½®"
echo "  - åºåˆ—é•¿åº¦: 1024 (å……åˆ†åˆ©ç”¨å¤§æ˜¾å­˜)"
echo ""

# æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if [ ! -f "deepspeed_single_a800_80g.json" ]; then
    echo "âŒ é…ç½®æ–‡ä»¶ deepspeed_single_a800_80g.json ä¸å­˜åœ¨ï¼"
    exit 1
fi

# å¯åŠ¨è®­ç»ƒ - å•GPUä¸éœ€è¦deepspeedå¯åŠ¨å™¨
python train_deepspeed.py \
    --preset 7b_mamba \
    --deepspeed_config deepspeed_single_a800_80g.json \
    --max_seq_length 1024 \
    --save_steps 500 \
    --eval_steps 250 \
    --logging_steps 50

echo "âœ… è®­ç»ƒå®Œæˆï¼" 