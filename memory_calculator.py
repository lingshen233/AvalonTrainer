#!/usr/bin/env python3
"""
7Bæ¨¡å‹æ˜¾å­˜éœ€æ±‚è®¡ç®—å™¨
"""

def calculate_memory_requirements():
    """è®¡ç®—çœŸæ­£7B Mambaæ¨¡å‹çš„æ˜¾å­˜éœ€æ±‚"""
    
    # çœŸæ­£7B Mambaå‚æ•°
    params = 6.89e9
    
    print('=== çœŸæ­£7B Mamba (6.89Bå‚æ•°) æ˜¾å­˜éœ€æ±‚ ===')
    
    # DataParallelæ¨¡å¼ï¼šæ¯å¼ å¡å®Œæ•´æ¨¡å‹
    print('\nğŸ“Š DataParallelæ¨¡å¼ï¼ˆæ¯å¼ GPUå®Œæ•´æ¨¡å‹ï¼‰:')
    model_memory = params * 2 / 1e9  # FP16æ¨¡å‹å‚æ•°
    optimizer_memory = params * 8 / 1e9  # Adamä¼˜åŒ–å™¨çŠ¶æ€
    gradient_memory = params * 2 / 1e9  # FP16æ¢¯åº¦
    
    print(f'æ¨¡å‹å‚æ•°(FP16): {model_memory:.2f}GB')
    print(f'ä¼˜åŒ–å™¨çŠ¶æ€(Adam): {optimizer_memory:.2f}GB') 
    print(f'æ¢¯åº¦å­˜å‚¨(FP16): {gradient_memory:.2f}GB')
    
    base_memory = model_memory + optimizer_memory + gradient_memory
    print(f'åŸºç¡€æ˜¾å­˜éœ€æ±‚: {base_memory:.2f}GB/GPU')
    
    # æ¿€æ´»å€¼å’Œæ€»éœ€æ±‚
    activation = 1 * 4096 * 4864 * 45 * 2 / 1e9  # ç®€åŒ–æ¿€æ´»å€¼
    total_dp = base_memory + activation + 3
    print(f'æ€»æ˜¾å­˜éœ€æ±‚: {total_dp:.1f}GB/GPU âŒ å¤ªé«˜äº†ï¼')
    
    # ZeROä¼˜åŒ–æ¨¡å¼
    print('\nğŸ”§ DeepSpeed ZeRO-2ä¼˜åŒ–ï¼ˆå‚æ•°å’Œæ¢¯åº¦åˆ†ç‰‡ï¼‰:')
    configs = [
        ("2å¼ 3090/4090", 2, 24), ("4å¼ 3090/4090", 4, 24),
        ("6å¼ 3090/4090", 6, 24), ("8å¼ 3090/4090", 8, 24),
        ("2å¼ vGPU", 2, 32), ("4å¼ vGPU", 4, 32)
    ]
    
    for name, num_gpus, gpu_memory in configs:
        # ZeRO-2ï¼šä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡ï¼Œæ¨¡å‹å‚æ•°åˆ†ç‰‡
        model_per_gpu = model_memory / num_gpus
        optimizer_per_gpu = optimizer_memory / num_gpus
        gradient_per_gpu = gradient_memory / num_gpus
        
        # æ¿€æ´»å€¼ï¼ˆæ¯GPUå¤„ç†1/num_gpusçš„æ•°æ®ï¼‰
        activation_per_gpu = activation / num_gpus
        
        total_zero = model_per_gpu + optimizer_per_gpu + gradient_per_gpu + activation_per_gpu + 2
        
        print(f'{name}: {total_zero:.1f}GB/GPU')
        print(f'  - æ¨¡å‹: {model_per_gpu:.1f}GB')
        print(f'  - ä¼˜åŒ–å™¨: {optimizer_per_gpu:.1f}GB')
        print(f'  - æ¢¯åº¦: {gradient_per_gpu:.1f}GB')
        print(f'  - æ¿€æ´»: {activation_per_gpu:.1f}GB')
        
        if total_zero <= gpu_memory:
            print(f'  âœ… å¯è¡Œï¼å‰©ä½™ {gpu_memory - total_zero:.1f}GB')
        else:
            print(f'  âŒ è¶…å‡º {total_zero - gpu_memory:.1f}GB')
        print()

def calculate_3b_requirements():
    """è®¡ç®—3Bæ¨¡å‹éœ€æ±‚ï¼ˆå¯¹æ¯”ï¼‰"""
    print('\n=== å¯¹æ¯”ï¼š3B Mamba (2.84Bå‚æ•°) ===')
    params = 2.84e9
    
    model_memory = params * 2 / 1e9
    optimizer_memory = params * 8 / 1e9
    gradient_memory = params * 2 / 1e9
    activation = 1 * 2048 * 3584 * 32 * 2 / 1e9
    
    total = model_memory + optimizer_memory + gradient_memory + activation + 2
    
    print(f'DataParallelæ¨¡å¼: {total:.1f}GB/GPU')
    if total <= 24:
        print('âœ… å•å¼ 24GB GPUå³å¯è¿è¡Œ!')
    else:
        print('âŒ ä»éœ€å¤šå¼ GPU')

if __name__ == "__main__":
    calculate_memory_requirements()
    calculate_3b_requirements() 