#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - éªŒè¯è®­ç»ƒæ¡†æ¶åŸºæœ¬åŠŸèƒ½
"""

import torch
import yaml
import subprocess
import sys
import os
from pathlib import Path

def test_dependencies():
    """æµ‹è¯•ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…"""
    print("ğŸ” æ£€æŸ¥ä¾èµ–åŒ…...")
    
    required_packages = [
        'torch', 'transformers', 'datasets', 
        'yaml', 'numpy', 'tqdm'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"  âœ… {package}")
        except ImportError:
            print(f"  âŒ {package} æœªå®‰è£…")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nâŒ ç¼ºå°‘ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…")
    return True

def test_cuda():
    """æµ‹è¯•CUDAç¯å¢ƒ"""
    print("\nğŸ” æ£€æŸ¥CUDAç¯å¢ƒ...")
    
    if torch.cuda.is_available():
        print(f"  âœ… CUDA å¯ç”¨")
        print(f"  GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            print(f"  GPU {i}: {props.name} ({props.total_memory/1e9:.1f}GB)")
        return True
    else:
        print("  âš ï¸ CUDA ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
        return False

def test_config_loading():
    """æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½"""
    print("\nğŸ” æµ‹è¯•é…ç½®æ–‡ä»¶...")
    
    config_files = ['config.yaml', 'config_transformer_4gpu.yaml']
    
    for config_file in config_files:
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                print(f"  âœ… {config_file} åŠ è½½æˆåŠŸ")
            except Exception as e:
                print(f"  âŒ {config_file} åŠ è½½å¤±è´¥: {e}")
                return False
        else:
            print(f"  âŒ {config_file} ä¸å­˜åœ¨")
            return False
    
    return True

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\nğŸ” æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    try:
        # æµ‹è¯•å¯¼å…¥
        from configs.base import ModelConfig
        from models import create_model
        
        # åˆ›å»ºå°å‹æµ‹è¯•é…ç½®
        test_config = ModelConfig(
            model_type='transformer',
            vocab_size=1000,
            max_seq_length=128,
            d_model=256,
            n_layers=2,
            n_heads=4,
            d_ff=512,
            dropout=0.1
        )
        
        # åˆ›å»ºæ¨¡å‹
        model = create_model('transformer', test_config)
        total_params = sum(p.numel() for p in model.parameters())
        
        print(f"  âœ… Transformeræ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"  å‚æ•°é‡: {total_params:,} ({total_params/1e6:.2f}M)")
        
        # æµ‹è¯•Mambaæ¨¡å‹
        test_config.model_type = 'mamba'
        test_config.d_state = 16
        test_config.d_conv = 4
        test_config.expand = 2
        
        model = create_model('mamba', test_config)
        total_params = sum(p.numel() for p in model.parameters())
        
        print(f"  âœ… Mambaæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"  å‚æ•°é‡: {total_params:,} ({total_params/1e6:.2f}M)")
        
        return True
        
    except Exception as e:
        print(f"  âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False

def test_training_script():
    """æµ‹è¯•è®­ç»ƒè„šæœ¬"""
    print("\nğŸ” æµ‹è¯•è®­ç»ƒè„šæœ¬...")
    
    # æµ‹è¯•åˆ—å‡ºæ¨¡å‹
    try:
        result = subprocess.run([sys.executable, 'train.py', '--list_models'], 
                              capture_output=True, text=True, timeout=30)
        if result.returncode == 0:
            print("  âœ… --list_models å·¥ä½œæ­£å¸¸")
        else:
            print(f"  âŒ --list_models å¤±è´¥: {result.stderr}")
            return False
    except Exception as e:
        print(f"  âŒ --list_models æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•dry run
    try:
        result = subprocess.run([sys.executable, 'train.py', '--dry_run'], 
                              capture_output=True, text=True, timeout=30)
        if result.returncode == 0:
            print("  âœ… --dry_run å·¥ä½œæ­£å¸¸")
        else:
            print(f"  âŒ --dry_run å¤±è´¥: {result.stderr}")
            return False
    except Exception as e:
        print(f"  âŒ --dry_run æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

def main():
    print("ğŸš€ å¼€å§‹å¿«é€Ÿæµ‹è¯•...")
    print("=" * 50)
    
    tests = [
        ("ä¾èµ–åŒ…æ£€æŸ¥", test_dependencies),
        ("CUDAç¯å¢ƒ", test_cuda),
        ("é…ç½®æ–‡ä»¶", test_config_loading),
        ("æ¨¡å‹åˆ›å»º", test_model_creation),
        ("è®­ç»ƒè„šæœ¬", test_training_script)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        if test_func():
            passed += 1
        else:
            print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
    
    print("\n" + "=" * 50)
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¡†æ¶å¯ä»¥æ­£å¸¸ä½¿ç”¨")
        return 0
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³é—®é¢˜")
        return 1

if __name__ == "__main__":
    exit(main()) 