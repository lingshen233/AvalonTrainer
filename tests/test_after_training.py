#!/usr/bin/env python3
"""
è®­ç»ƒåå¿«é€Ÿæµ‹è¯•è„šæœ¬
æµ‹è¯•åˆšè®­ç»ƒå®Œæˆçš„æ¨¡å‹
"""

import os
import sys
import argparse
import torch
from configs.base import ModelConfig
from models import create_model

def remove_module_prefix(state_dict):
    """ç§»é™¤DDPæ¨¡å‹çš„module.å‰ç¼€"""
    new_state_dict = {}
    for k, v in state_dict.items():
        if k.startswith('module.'):
            new_state_dict[k[7:]] = v  # ç§»é™¤'module.'å‰ç¼€
        else:
            new_state_dict[k] = v
    return new_state_dict

def test_model(checkpoint_path):
    """æµ‹è¯•æ¨¡å‹"""
    print("============================================================")
    print(f"ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å‹: {checkpoint_path}")
    
    if not os.path.exists(checkpoint_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        return False
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
    except Exception as e:
        print(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
        return False
    
    # è·å–é…ç½®
    if 'config' not in checkpoint:
        print("âŒ æ£€æŸ¥ç‚¹ä¸­ç¼ºå°‘é…ç½®ä¿¡æ¯")
        return False
    
    config_dict = checkpoint['config']
    print(f"ğŸ“‹ æ¨¡å‹é…ç½®: {config_dict['model_type']}")
    
    # åˆ›å»ºæ¨¡å‹é…ç½®
    model_config = ModelConfig(**config_dict)
    
    # åˆ›å»ºæ¨¡å‹
    print("ğŸ”§ åˆ›å»ºæ¨¡å‹...")
    try:
        model = create_model(model_config.model_type, model_config)
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ¨¡å‹å¤±è´¥: {e}")
        return False
    
    # å¤„ç†DDPæ¨¡å‹çš„state_dict
    state_dict = checkpoint['model_state_dict']
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯DDPæ¨¡å‹ï¼ˆé”®åæœ‰module.å‰ç¼€ï¼‰
    has_module_prefix = any(k.startswith('module.') for k in state_dict.keys())
    if has_module_prefix:
        print("ğŸ”„ æ£€æµ‹åˆ°DDPæ¨¡å‹ï¼Œç§»é™¤module.å‰ç¼€...")
        state_dict = remove_module_prefix(state_dict)
    
    # åŠ è½½æ¨¡å‹å‚æ•°
    print("ğŸ“¥ åŠ è½½æ¨¡å‹å‚æ•°...")
    try:
        model.load_state_dict(state_dict, strict=True)
        print("âœ… æ¨¡å‹å‚æ•°åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å‚æ•°å¤±è´¥: {e}")
        return False
    
    # è®¾ç½®è¯„ä¼°æ¨¡å¼
    model.eval()
    
    # è·å–è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è®¡ç®—æ¨¡å‹å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ“Š æ¨¡å‹å‚æ•°é‡: {total_params:,} ({total_params/1e6:.1f}M)")
    
    # ç®€å•çš„å‰å‘ä¼ æ’­æµ‹è¯•
    print("ğŸ§ª æ‰§è¡Œå‰å‘ä¼ æ’­æµ‹è¯•...")
    try:
        batch_size = 2
        seq_length = 128
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_input = torch.randint(0, model_config.vocab_size, (batch_size, seq_length)).to(device)
        
        with torch.no_grad():
            outputs = model(test_input)
        
        # å¤„ç†ä¸åŒç±»å‹çš„è¾“å‡º
        if isinstance(outputs, dict):
            # å­—å…¸è¾“å‡ºï¼ˆå¸¸è§äºMambaæ¨¡å‹ï¼‰
            if 'logits' in outputs:
                output_shape = outputs['logits'].shape
                print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼ˆå­—å…¸è¾“å‡ºï¼‰")
                print(f"   è¾“å…¥å½¢çŠ¶: {test_input.shape}")
                print(f"   è¾“å‡ºlogitså½¢çŠ¶: {output_shape}")
                logits = outputs['logits']
            else:
                # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå¼ é‡è¾“å‡º
                tensor_outputs = {k: v for k, v in outputs.items() if torch.is_tensor(v)}
                if tensor_outputs:
                    key, tensor = next(iter(tensor_outputs.items()))
                    output_shape = tensor.shape
                    print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼ˆå­—å…¸è¾“å‡ºï¼‰")
                    print(f"   è¾“å…¥å½¢çŠ¶: {test_input.shape}")
                    print(f"   è¾“å‡º{key}å½¢çŠ¶: {output_shape}")
                    logits = tensor
                else:
                    print(f"âš ï¸  æ— æ³•è¯†åˆ«è¾“å‡ºæ ¼å¼: {list(outputs.keys())}")
                    return True  # è‡³å°‘æ¨¡å‹è¿è¡Œäº†
        elif hasattr(outputs, 'logits'):
            # å‘½åå…ƒç»„è¾“å‡ºï¼ˆå¸¸è§äºTransformeræ¨¡å‹ï¼‰
            output_shape = outputs.logits.shape
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼ˆå‘½åå…ƒç»„è¾“å‡ºï¼‰")
            print(f"   è¾“å…¥å½¢çŠ¶: {test_input.shape}")
            print(f"   è¾“å‡ºlogitså½¢çŠ¶: {output_shape}")
            logits = outputs.logits
        else:
            # ç›´æ¥å¼ é‡è¾“å‡º
            output_shape = outputs.shape
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼ˆå¼ é‡è¾“å‡ºï¼‰")
            print(f"   è¾“å…¥å½¢çŠ¶: {test_input.shape}")
            print(f"   è¾“å‡ºå½¢çŠ¶: {output_shape}")
            logits = outputs
        
        # ç®€å•çš„æ–‡æœ¬ç”Ÿæˆæµ‹è¯•
        print("ğŸ“ æ‰§è¡Œæ–‡æœ¬ç”Ÿæˆæµ‹è¯•...")
        prompt = torch.randint(0, 1000, (1, 10)).to(device)  # ç®€å•çš„æç¤º
        
        with torch.no_grad():
            for i in range(5):  # ç”Ÿæˆ5ä¸ªtoken
                outputs = model(prompt)
                
                # æå–logits
                if isinstance(outputs, dict):
                    if 'logits' in outputs:
                        current_logits = outputs['logits']
                    else:
                        # è·å–ç¬¬ä¸€ä¸ªå¼ é‡
                        tensor_outputs = {k: v for k, v in outputs.items() if torch.is_tensor(v)}
                        current_logits = next(iter(tensor_outputs.values()))
                elif hasattr(outputs, 'logits'):
                    current_logits = outputs.logits
                else:
                    current_logits = outputs
                
                next_token = torch.argmax(current_logits[:, -1, :], dim=-1, keepdim=True)
                prompt = torch.cat([prompt, next_token], dim=1)
        
        print(f"âœ… æ–‡æœ¬ç”Ÿæˆæµ‹è¯•æˆåŠŸ")
        print(f"   ç”Ÿæˆåºåˆ—é•¿åº¦: {prompt.shape[1]}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description="è®­ç»ƒåæ¨¡å‹æµ‹è¯•")
    parser.add_argument("--checkpoint", type=str, default="checkpoints/final_model.pt", 
                       help="æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„")
    
    args = parser.parse_args()
    
    success = test_model(args.checkpoint)
    
    success_count = 1 if success else 0
    print(f"\nğŸ¯ æµ‹è¯•å®Œæˆ: {success_count}/1 æˆåŠŸ")
    
    if success:
        print("âœ… æ¨¡å‹è¿è¡Œæ­£å¸¸ï¼")
        print("ğŸ’¡ ä¸‹ä¸€æ­¥å¯ä»¥:")
        print("   1. è¿è¡Œå®Œæ•´åŸºå‡†æµ‹è¯•: python test_benchmark.py")
        print("   2. å°è¯•è®­ç»ƒæ›´å¤§æ¨¡å‹: python train.py --preset 1b_transformer")
        print("   3. è¿›è¡Œå®é™…æ¨ç†ä»»åŠ¡")
    else:
        print("âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")

if __name__ == "__main__":
    main() 